version: '3.7'

services:

  # The 'setup' service runs a one-off script which initializes users inside
  # Elasticsearch — such as 'logstash_internal' and 'kibana_system' — with the
  # values of the passwords defined in the '.env' file. It also creates the
  # roles required by some of these users.
  #
  # This task only needs to be performed once, during the *initial* startup of
  # the stack. Any subsequent run will reset the passwords of existing users to
  # the values defined inside the '.env' file, and the built-in roles to their
  # default permissions.
  #
  # By default, it is excluded from the services started by 'docker compose up'
  # due to the non-default profile it belongs to. To run it, either provide the
  # '--profile=setup' CLI flag to Compose commands, or "up" the service by name
  # such as 'docker compose up setup'.
  setup:
    profiles:
      - setup
    build:
      context: setup/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    init: true
    volumes:
      - /home/ubuntu/jenkins_home/workspace/ELKK/elkk/setup/entrypoint.sh:/entrypoint.sh:ro,Z
      - /home/ubuntu/jenkins_home/workspace/ELKK/elkk/setup/lib.sh:/lib.sh:ro,Z
      - /home/ubuntu/jenkins_home/workspace/ELKK/elkk/setup/roles:/roles:ro,Z
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
      METRICBEAT_INTERNAL_PASSWORD: ${METRICBEAT_INTERNAL_PASSWORD:-}
      FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
      HEARTBEAT_INTERNAL_PASSWORD: ${HEARTBEAT_INTERNAL_PASSWORD:-}
      MONITORING_INTERNAL_PASSWORD: ${MONITORING_INTERNAL_PASSWORD:-}
      BEATS_SYSTEM_PASSWORD: ${BEATS_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch

  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - /home/ubuntu/jenkins_home/workspace/ELKK/elkk/elasticsearch/config/elasticsearch.yml:/var/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch:/var/elasticsearch/data:Z
    ports:
      - ${ELASTIC_PORT_1}:${ELASTIC_PORT_1}
      - ${ELASTIC_PORT_2}:${ELASTIC_PORT_2}
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - elk
      - ubuntu_infra
    restart: unless-stopped

  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - /home/ubuntu/jenkins_home/workspace/ELKK/elkk/logstash/config/logstash.yml:/var/logstash/config/logstash.yml:ro,Z
      - /home/ubuntu/jenkins_home/workspace/ELKK/elkk/logstash/pipeline:/var/logstash/pipeline:ro,Z
    ports:
      - ${LOGSTASH_PORT}:${LOGSTASH_PORT}/tcp
      - ${LOGSTASH_PORT}:${LOGSTASH_PORT}/udp
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    networks:
      - elk
      - ubuntu_infra
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    build:
      context: kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - /home/ubuntu/jenkins_home/workspace/ELKK/elkk/kibana/config/kibana.yml:/var/kibana/config/kibana.yml:ro,Z
    ports:
      - ${KIBANA_PORT}:${KIBANA_PORT}
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - elk
      - ubuntu_infra
    depends_on:
      - elasticsearch
    restart: unless-stopped

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:latest
    ports:
      - "${ZOOKEEPER_PORT}:${ZOOKEEPER_CLIENT_PORT}"
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT}
      ZOOKEEPER_TICK_TIME: ${ZOOKEEPER_TICK_TIME}
    networks:
      - elk
      - ubuntu_infra

  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "${KAFKA_PORT}:${KAFKA_PORT}"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:${ZOOKEEPER_CLIENT_PORT}
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:${KAFKA_SUB_PORT},PLAINTEXT_HOST://${SERVER_IP}:${KAFKA_PORT}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "${RANK_LOG}:1:1"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - elk
      - ubuntu_infra

networks:
  elk:
    driver: bridge
  ubuntu_infra:
    external: true

volumes:
  elasticsearch:
